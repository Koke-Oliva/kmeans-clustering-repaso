# K-means Clustering - Repaso

Este proyecto contiene un repaso detallado del algoritmo de **K-means Clustering** utilizando datos simulados. Se trata de un ejercicio de aprendizaje pr谩ctico para explorar el comportamiento del algoritmo y mejorar la comprensi贸n de la segmentaci贸n de datos. El proyecto est谩 implementado en Python usando **Jupyter Notebook**.

##  ndice de Contenidos
1. Generaci贸n de datos aleatorios
2. Visualizaci贸n de los datos
3. Aplicaci贸n del algoritmo K-means
4. M茅todo del Codo
5. Distancia intra-cluster
6. M茅tricas de validaci贸n
7. Gr谩fica comparativa de 铆ndices de validaci贸n
8. An谩lisis predictivo
9. An谩lisis de la varianza intra-cluster
10. Librer铆as utilizadas

## Descripci贸n del Proyecto
El objetivo de este proyecto es realizar un repaso pr谩ctico sobre el uso del algoritmo de **K-means** para segmentar datos generados aleatoriamente. A lo largo del notebook se exploran distintas etapas del proceso de clustering, desde la generaci贸n de los datos hasta la evaluaci贸n de la calidad de los clusters formados.

### 1. Generaci贸n de Datos Aleatorios
Los datos se generaron de manera aleatoria usando `numpy`, con el objetivo de tener cuatro grupos definidos. Esto permite un mejor control sobre los datos y facilita la interpretaci贸n de los resultados del clustering.

### 2. Visualizaci贸n de los Datos
Se utiliz贸 `matplotlib` y `seaborn` para visualizar los datos generados, lo cual facilit贸 la comprensi贸n de su distribuci贸n antes de aplicar el algoritmo.

### 3. Aplicaci贸n del Algoritmo K-means
El algoritmo de K-means se implement贸 utilizando `scikit-learn`. Se probaron diferentes valores para el n煤mero de clusters con el objetivo de identificar el mejor ajuste para los datos.

### 4. M茅todo del Codo
El **m茅todo del codo** se utiliz贸 para determinar el n煤mero 贸ptimo de clusters. Se calcul贸 la suma de errores cuadr谩ticos (SSE) para diferentes cantidades de clusters y se gener贸 una gr谩fica que permite visualizar el punto de inflexi贸n.

### 5. Distancia Intra-cluster
Se calcul贸 la **distancia intra-cluster** para evaluar la compacidad de los clusters formados, un m茅todo importante para entender qu茅 tan cercanos est谩n los puntos dentro de un mismo cluster.

### 6. M茅tricas de Validaci贸n
Se aplicaron diferentes m茅tricas de validaci贸n para medir la calidad de los clusters, como el **coeficiente de silueta**. Adem谩s, se gener贸 una gr谩fica comparativa para analizar los 铆ndices obtenidos.

### 7. An谩lisis Predictivo
Una vez definidos los clusters, se realiz贸 un **an谩lisis predictivo** usando los resultados del modelo para asignar nuevas muestras a los clusters formados.

### 8. An谩lisis de la Varianza Intra-cluster
Se evalu贸 la varianza intra-cluster para comprobar la homogeneidad de los datos dentro de cada cluster.

## Tecnolog铆as Utilizadas
- **Python** con **Jupyter Notebook**
- **Pandas** y **NumPy** para la manipulaci贸n de datos
- **Scikit-learn** para aplicar el algoritmo K-means
- **Matplotlib** y **Seaborn** para la visualizaci贸n de datos

## C贸mo Ejecutar el Proyecto
1. Clona este repositorio:
   ```sh
   git clone https://github.com/Koke-Oliva/kmeans-clustering-repaso.git
   ```
2. Aseg煤rate de tener instaladas las librer铆as necesarias. Puedes instalarlas ejecutando:
   ```sh
   pip install -r requirements.txt
   ```
3. Abre el archivo `.ipynb` en **Jupyter Notebook** y sigue los pasos descritos.

## Resultados
Los resultados incluyen visualizaciones de los clusters y evaluaciones detalladas de la calidad de los mismos. Estos resultados ayudan a comprender mejor la agrupaci贸n lograda por el algoritmo y c贸mo se relacionan los datos entre s铆.

## Pr贸ximos Pasos
- Aplicar estas t茅cnicas a un conjunto de datos m谩s complejo y real.
- Utilizar otros algoritmos de clustering para comparar resultados.

## Contacto
Si deseas m谩s informaci贸n o tienes alguna duda, no dudes en contactarme a trav茅s de [mi perfil de GitHub](https://github.com/Koke-Oliva).

